{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating training datasets\n",
    "This notebook generates the training datasets with varying numbers of adjacent wells used as features. It writes out the training data to `.csv` files for use in training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING with 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jrp4932\\AppData\\Local\\Continuum\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\ipykernel_launcher.py:105: FutureWarning: The join_axes-keyword is deprecated. Use .reindex or .reindex_like on the result to achieve the same functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the features\n",
      "normalizing the truncation\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f2c947316184>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhood\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mno_of_neighbors\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             selected = (\n\u001b[1;32m--> 229\u001b[1;33m                 \u001b[0mrolling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhood\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mno_of_neighbors\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m                 \u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[1;33m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def flatten(A):\n",
    "    'Flatttens lists'\n",
    "    rt = []\n",
    "    for i in A:\n",
    "        if isinstance(i,list): rt.extend(flatten(i))\n",
    "        else: rt.append(i)\n",
    "    return rt\n",
    "\n",
    "names = [\n",
    "    \"one\",\n",
    "    \"two\",\n",
    "    \"three\",\n",
    "    \n",
    "]  \n",
    "# this creates dummy names for the formations\n",
    "\n",
    "number_of_layers = (\n",
    "    2\n",
    ")\n",
    "# this is the number of tops you want in your training data\n",
    "\n",
    "smallest = -5\n",
    "largest = 12\n",
    "step = 0.2\n",
    "\n",
    "# this loop walks through and creates the training data with adjacent wells as features\n",
    "\n",
    "for i in range(1,300):\n",
    "    # i is the number of adjacent wells \n",
    "    no_of_neighbors = i\n",
    "\n",
    "    np.random.seed(19)\n",
    "    df = pd.DataFrame()\n",
    "    locations = pd.DataFrame()\n",
    "    elevation_random = sorted(\n",
    "        np.random.uniform(smallest, largest, number_of_layers - 1)\n",
    "    )\n",
    "\n",
    "    print(f\"STARTING with {no_of_neighbors}\")\n",
    "    # Creating the truncation dataset\n",
    "    for j in np.arange(smallest, largest, step):\n",
    "        rolling = pd.DataFrame()\n",
    "        for i in range(len(names[0 : number_of_layers - 1])):\n",
    "            basement = 0.001 + (10 / j) * np.sin(\n",
    "                1 - np.arange(0, 40, 0.1) / (j * 10) + 0.001\n",
    "            )\n",
    "            elevation = np.full(400, j)\n",
    "            topbasement = np.where(basement > elevation, elevation, basement)\n",
    "            rolling[\"zero\"] = topbasement\n",
    "            layer_elevation = (\n",
    "                0.001\n",
    "                + (10 / j) * np.sin(1 - np.arange(0, 40, 0.1) / (j * 10) + 0.001)\n",
    "                + elevation_random[i]\n",
    "            )\n",
    "            layer_elevation = np.where(\n",
    "                layer_elevation > elevation, elevation, layer_elevation\n",
    "            )\n",
    "            rolling[names[i]] = layer_elevation\n",
    "        x = np.arange(0, 40, 0.1)\n",
    "        y = np.random.randint(0, 10, len(x))\n",
    "        if j % 0.2 > 0.1:\n",
    "            rolling[\"ex\"] = x * np.cos(-j / 2) - y * np.sin(-j / 2)\n",
    "            rolling[\"ey\"] = y * np.cos(-j / 2) - x * np.sin(-j / 2)\n",
    "        else:\n",
    "            rolling[\"ex\"] = x * np.cos(j / 2) - y * np.sin(j / 2)\n",
    "            rolling[\"ey\"] = y * np.cos(j / 2) - x * np.sin(j / 2)\n",
    "        for k in range(100):\n",
    "            rolling.iloc[\n",
    "                np.random.randint(0, 399),\n",
    "                np.random.randint(0, number_of_layers - 1),\n",
    "            ] = 0\n",
    "        hood = squareform(pdist(rolling.iloc[:, -2:]))\n",
    "        neighbors = []\n",
    "        for i in enumerate(hood.argsort()[0:, 1 : no_of_neighbors + 1]):\n",
    "            selected = (\n",
    "                rolling.iloc[hood.argsort()[i[0], 1 : no_of_neighbors + 1], 0:-2]\n",
    "                .stack()\n",
    "                .to_frame()\n",
    "                .T\n",
    "            )\n",
    "            selected.columns = selected.columns.droplevel()\n",
    "            neighbors.append(selected)\n",
    "        frame = pd.concat(neighbors, sort=False)\n",
    "        frame.index = range(len(frame))\n",
    "        neighborhood = pd.concat([rolling.iloc[:, :-2], frame], axis=1)\n",
    "        thicknesses = neighborhood.diff(axis=1)\n",
    "        thicknesses[thicknesses < 0] = 0\n",
    "        thicknesses.drop(columns=\"zero\", inplace=True)\n",
    "        locations = pd.concat((locations, rolling.iloc[:, -2:]))\n",
    "        df = pd.concat((df, thicknesses))\n",
    "    logged = df.apply(\n",
    "        np.log\n",
    "    )  # take the log of thicknesses for feature engineering\n",
    "    powered = df.apply(\n",
    "        lambda x: x ** 10\n",
    "    )  # calculates the power values of thickness for another feature\n",
    "    at = (\n",
    "        pd.concat([df, logged, powered, locations], axis=1, join_axes=[df.index])\n",
    "        .dropna()\n",
    "        .replace(-np.inf, 0)\n",
    "    )\n",
    "    print('Getting the features')\n",
    "    features = ['thickness',\n",
    "    'thickness neighbor 1',\n",
    "    'thickness neighbor 2',\n",
    "    'thickness neighbor 3',\n",
    "    'thickness neighbor 4',\n",
    "    'thickness neighbor 5',\n",
    "    'thickness neighbor 6',\n",
    "    'thickness neighbor 7',\n",
    "    'thickness neighbor 8',\n",
    "    'thickness neighbor 9',\n",
    "    'thickness neighbor 10',\n",
    "    'thickness neighbor 11',\n",
    "    'thickness neighbor 12',\n",
    "    'thickness neighbor 13',\n",
    "    'thickness neighbor 14',\n",
    "    'thickness neighbor 15',\n",
    "    'thickness neighbor 16',\n",
    "    'thickness neighbor 17',\n",
    "    'thickness neighbor 18',\n",
    "    'thickness neighbor 19',\n",
    "    'thickness neighbor 20',\n",
    "    'thickness natural log',\n",
    "    'thickness natural log neighbor 1',\n",
    "    'thickness natural log neighbor 2',\n",
    "    'thickness natural log neighbor 3',\n",
    "    'thickness natural log neighbor 4',\n",
    "    'thickness natural log neighbor 5',\n",
    "    'thickness natural log neighbor 6',\n",
    "    'thickness natural log neighbor 7',\n",
    "    'thickness natural log neighbor 8',\n",
    "    'thickness natural log neighbor 9',\n",
    "    'thickness natural log neighbor 10',\n",
    "    'thickness natural log neighbor 11',\n",
    "    'thickness natural log neighbor 12',\n",
    "    'thickness natural log neighbor 13',\n",
    "    'thickness natural log neighbor 14',\n",
    "    'thickness natural log neighbor 15',\n",
    "    'thickness natural log neighbor 16',\n",
    "    'thickness natural log neighbor 17',\n",
    "    'thickness natural log neighbor 18',\n",
    "    'thickness natural log neighbor 19',\n",
    "    'thickness natural log neighbor 20',\n",
    "    'thickness power',\n",
    "    'thickness power neighbor 1',\n",
    "    'thickness power neighbor 2',\n",
    "    'thickness power neighbor 3',\n",
    "    'thickness power neighbor 4',\n",
    "    'thickness power neighbor 5',\n",
    "    'thickness power neighbor 6',\n",
    "    'thickness power neighbor 7',\n",
    "    'thickness power neighbor 8',\n",
    "    'thickness power neighbor 9',\n",
    "    'thickness power neighbor 10',\n",
    "    'thickness power neighbor 11',\n",
    "    'thickness power neighbor 12',\n",
    "    'thickness power neighbor 13',\n",
    "    'thickness power neighbor 14',\n",
    "    'thickness power neighbor 15',\n",
    "    'thickness power neighbor 16',\n",
    "    'thickness power neighbor 17',\n",
    "    'thickness power neighbor 18',\n",
    "    'thickness power neighbor 19',\n",
    "    'thickness power neighbor 20',\n",
    "    'x location',\n",
    "    'y location',\n",
    "    'class'\n",
    "    ]\n",
    "\n",
    "    featured = [features[0:no_of_neighbors+1], features[21:22+no_of_neighbors], features[42:43+no_of_neighbors], features[-3:]]\n",
    "    flat_features = flatten(featured)\n",
    "\n",
    "    print('normalizing the truncation')\n",
    "    # NORMALIZING THE TRUNCATION DATA\n",
    "    # normalize the data from 0 to 1\n",
    "    normalized_dfa = (at - at.min()) / (at.max() - at.min()).replace(0, 0.00001)\n",
    "    normalized_locations = (locations - locations.min()) / (\n",
    "        locations.max() - locations.min()\n",
    "    )\n",
    "    x = normalized_locations.ex.values\n",
    "    y = normalized_locations.ey.values\n",
    "    normalized_dfa[\"ex\"] = x\n",
    "    normalized_dfa[\"ey\"] = y\n",
    "\n",
    "    np.random.seed(19)\n",
    "\n",
    "    df_onlap = pd.DataFrame()\n",
    "    locations = pd.DataFrame()\n",
    "    \n",
    "    # Creating the onlap data\n",
    "    for j in np.arange(smallest, largest, step):\n",
    "        rolling = pd.DataFrame()\n",
    "        for i in range(len(names[0 : number_of_layers - 1])):\n",
    "            basement = 0.001 + (10 / j) * np.sin(\n",
    "                1 - np.arange(0, 40, 0.1) / (j * 10) + 0.001\n",
    "            )\n",
    "            elevation = np.full(400, j)\n",
    "            topbasement = np.where(basement > elevation, elevation, basement)\n",
    "            rolling[\"zero\"] = topbasement\n",
    "            strat_elevation = np.full(400, elevation_random[i])\n",
    "            onlap = np.where(strat_elevation > basement, strat_elevation, basement)\n",
    "            layer_elevation = np.where(onlap > elevation, elevation, onlap)\n",
    "            rolling[names[i]] = layer_elevation\n",
    "        x = np.arange(0, 40, 0.1)\n",
    "        y = np.random.randint(0, 10, len(x))\n",
    "        if j % 0.2 > 0.1:\n",
    "            rolling[\"ex\"] = x * np.cos(-j / 2) - y * np.sin(-j / 2)\n",
    "            rolling[\"ey\"] = y * np.cos(-j / 2) - x * np.sin(-j / 2)\n",
    "        else:\n",
    "            rolling[\"ex\"] = x * np.cos(j / 2) - y * np.sin(j / 2)\n",
    "            rolling[\"ey\"] = y * np.cos(j / 2) - x * np.sin(j / 2)\n",
    "        for k in range(100):\n",
    "            rolling.iloc[\n",
    "                np.random.randint(0, 399),\n",
    "                np.random.randint(0, number_of_layers - 1),\n",
    "            ] = 0\n",
    "        hood = squareform(pdist(rolling.iloc[:, -2:]))\n",
    "        neighbors = []\n",
    "        for i in enumerate(hood.argsort()[0:, 1 : no_of_neighbors + 1]):\n",
    "            selected = (\n",
    "                rolling.iloc[hood.argsort()[i[0], 1 : no_of_neighbors + 1], 0:-2]\n",
    "                .stack()\n",
    "                .to_frame()\n",
    "                .T\n",
    "            )\n",
    "            selected.columns = selected.columns.droplevel()\n",
    "            neighbors.append(selected)\n",
    "        frame = pd.concat(neighbors, sort=False)\n",
    "        frame.index = range(len(frame))\n",
    "        neighborhood = pd.concat([rolling.iloc[:, :-2], frame], axis=1)\n",
    "        thicknesses = neighborhood.diff(axis=1)\n",
    "        thicknesses[thicknesses < 0] = 0\n",
    "        thicknesses.drop(columns=\"zero\", inplace=True)\n",
    "        locations = pd.concat((locations, rolling.iloc[:, -2:]))\n",
    "        df_onlap = pd.concat((df_onlap, thicknesses))\n",
    "    onlaplogged = df_onlap.apply(\n",
    "        np.log\n",
    "    )  # take the log of thicknesses for feature engineering\n",
    "    onlappowered = df_onlap.apply(\n",
    "        lambda x: x ** 10\n",
    "    )  # calculates the power values of thickness for another feature\n",
    "    ot = (\n",
    "        pd.concat(\n",
    "            [df_onlap, onlaplogged, onlappowered, locations],\n",
    "            axis=1,\n",
    "            join_axes=[df_onlap.index],\n",
    "        )\n",
    "        .dropna()\n",
    "        .replace(-np.inf, 0)\n",
    "    )\n",
    "    print('normalizing the onlap')\n",
    "    # NORMALIZING THE ONLAP\n",
    "    # normalize the data from 0 to 1\n",
    "    normalized_dfo = (ot - ot.min()) / (ot.max() - ot.min()).replace(0, 0.00001)\n",
    "    normalized_locations = (locations - locations.min()) / (\n",
    "        locations.max() - locations.min()\n",
    "    )\n",
    "    x = normalized_locations.ex.values\n",
    "    y = normalized_locations.ey.values\n",
    "    normalized_dfo[\"ex\"] = x\n",
    "    normalized_dfo[\"ey\"] = y\n",
    "\n",
    "    np.random.seed(19)\n",
    "\n",
    "    df_horizontal = pd.DataFrame()\n",
    "    locations = pd.DataFrame()\n",
    "    # Creating the horizontally stratified data\n",
    "    for j in np.arange(smallest, largest, step):\n",
    "        rolling = pd.DataFrame()\n",
    "        for i in range(len(names[0 : number_of_layers - 1])):\n",
    "            basement = np.full(400, 0) - np.random.rand(400) / 100\n",
    "            elevation = np.full(400, j)\n",
    "            topbasement = np.where(basement > elevation, elevation, basement)\n",
    "            rolling[\"zero\"] = topbasement\n",
    "            strat_elevation = np.full(400, elevation_random[i])\n",
    "            layer_elevation = np.where(\n",
    "                strat_elevation > elevation, elevation, strat_elevation\n",
    "            )\n",
    "            rolling[names[i]] = layer_elevation\n",
    "        x = np.arange(0, 40, 0.1)\n",
    "        y = np.random.randint(0, 10, len(x))\n",
    "        if j % 0.2 > 0.1:\n",
    "            rolling[\"ex\"] = x * np.cos(-j / 2) - y * np.sin(-j / 2)\n",
    "            rolling[\"ey\"] = y * np.cos(-j / 2) - x * np.sin(-j / 2)\n",
    "        else:\n",
    "            rolling[\"ex\"] = x * np.cos(j / 2) - y * np.sin(j / 2)\n",
    "            rolling[\"ey\"] = y * np.cos(j / 2) - x * np.sin(j / 2)\n",
    "        for k in range(100):\n",
    "            rolling.iloc[\n",
    "                np.random.randint(0, 399),\n",
    "                np.random.randint(0, number_of_layers - 1),\n",
    "            ] = 0\n",
    "        hood = squareform(pdist(rolling.iloc[:, -2:]))\n",
    "        neighbors = []\n",
    "        for i in enumerate(hood.argsort()[0:, 1 : no_of_neighbors + 1]):\n",
    "            selected = (\n",
    "                rolling.iloc[hood.argsort()[i[0], 1 : no_of_neighbors + 1], 0:-2]\n",
    "                .stack()\n",
    "                .to_frame()\n",
    "                .T\n",
    "            )\n",
    "            selected.columns = selected.columns.droplevel()\n",
    "            neighbors.append(selected)\n",
    "        frame = pd.concat(neighbors, sort=False)\n",
    "        frame.index = range(len(frame))\n",
    "        neighborhood = pd.concat([rolling.iloc[:, :-2], frame], axis=1)\n",
    "        thicknesses = neighborhood.diff(axis=1)\n",
    "        thicknesses[thicknesses < 0] = 0\n",
    "        thicknesses.drop(columns=\"zero\", inplace=True)\n",
    "        locations = pd.concat((locations, rolling.iloc[:, -2:]))\n",
    "        df_horizontal = pd.concat((df_horizontal, thicknesses))\n",
    "    horizlogged = df_horizontal.apply(\n",
    "        np.log\n",
    "    )  # take the log of thicknesses for feature engineering\n",
    "    horizpowered = df_horizontal.apply(\n",
    "        lambda x: x ** 10\n",
    "    )  # calculates the power values of thickness for another feature\n",
    "    hs = (\n",
    "        pd.concat(\n",
    "            [df_horizontal, horizlogged, horizpowered, locations],\n",
    "            axis=1,\n",
    "            join_axes=[df_horizontal.index],\n",
    "        )\n",
    "        .dropna()\n",
    "        .replace(-np.inf, 0)\n",
    "    )\n",
    "    print('normalizing the horizontal strata')\n",
    "    # NORMALIZING THE DATA\n",
    "    # normalize the data from 0 to 1\n",
    "    normalized_dfh = (hs - hs.min()) / (hs.max() - hs.min()).replace(0, 0.00001)\n",
    "    normalized_locations = (locations - locations.min()) / (\n",
    "        locations.max() - locations.min()\n",
    "    )\n",
    "    x = normalized_locations.ex.values\n",
    "    y = normalized_locations.ey.values\n",
    "    normalized_dfh[\"ex\"] = x\n",
    "    normalized_dfh[\"ey\"] = y\n",
    "\n",
    "    # now assign classes to the datasets, 1 is onlap, 0 is angular unconformity\n",
    "    normalized_dfa[\"class\"] = 0 #truncation\n",
    "    normalized_dfo[\"class\"] = 1 #onlap\n",
    "    normalized_dfh[\"class\"] = 2 #horizontal\n",
    "\n",
    "    dataset = pd.concat((normalized_dfa, normalized_dfo, normalized_dfh))\n",
    "    dataset.columns = flat_features\n",
    "    print(f'saving the training data for {no_of_neighbors}')\n",
    "    dataset.to_csv(\n",
    "        str(number_of_layers) + \"_layers_\" + str(no_of_neighbors)+\"neighbors.csv\"\n",
    "    )\n",
    "    print(f'Done with {no_of_neighbors} neighbors')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
