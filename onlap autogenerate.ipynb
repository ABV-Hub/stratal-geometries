{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import itertools\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "import fiona\n",
    "\n",
    "%matplotlib inline\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_tops = 2\n",
    "no_of_neighbors = 20\n",
    "\n",
    "dataset = pd.read_csv(\n",
    "    r\"D:/jupyter/\" + str(number_of_tops) + \"layers\"+str(no_of_neighbors)+\"neighbors.csv\",\n",
    "    index_col=[0],\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# next let's split our toy data into training and test sets, choose how much with test_size of the data becomes the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset.iloc[0:, 0:-1].values,\n",
    "    dataset.iloc[0:, -1].values,\n",
    "    test_size=0.1,\n",
    "    random_state=86,\n",
    ")\n",
    "tops_api = pd.read_csv(r\"D:\\jupyter\\EarlyWSGS\\ftunion.csv\").fillna(\n",
    "    0\n",
    ")  # this file is available in the unconformity or onlap folder in the repo\n",
    "\n",
    "iterable = [\"Kfh\", \"Klz\", \"Kll\", \"Klr\", \"Kl\", \"Tfc\", \"Tfb\", \"Tfob\", \"Tfu\"]\n",
    "topcombos = list(zip(iterable, iterable[1:]))\n",
    "topcombos.append((\"Kfh\", \"Kl\"))\n",
    "topcombos.append((\"Kl\", \"Tfu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=10)\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  32 out of  32 | elapsed: 39.7min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_params = {\n",
    "    'n_neighbors' : [4,5,11,19],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan'],\n",
    "\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(KNeighborsClassifier(), grid_params, verbose=1, cv=2, n_jobs =5)\n",
    "gs_results = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999891067538126"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'euclidean', 'n_neighbors': 4, 'weights': 'distance'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=4, weights='distance', metric='euclidean')\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jesse.pisel\\AppData\\Local\\Continuum\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\geopandas\\io\\file.py:108: FionaDeprecationWarning: Use fiona.Env() instead.\n",
      "  with fiona.drivers():\n",
      "C:\\Users\\jesse.pisel\\AppData\\Local\\Continuum\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\geopandas\\io\\file.py:108: FionaDeprecationWarning: Use fiona.Env() instead.\n",
      "  with fiona.drivers():\n",
      "C:\\Users\\jesse.pisel\\AppData\\Local\\Continuum\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\geopandas\\io\\file.py:108: FionaDeprecationWarning: Use fiona.Env() instead.\n",
      "  with fiona.drivers():\n",
      "C:\\Users\\jesse.pisel\\AppData\\Local\\Continuum\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\geopandas\\io\\file.py:108: FionaDeprecationWarning: Use fiona.Env() instead.\n",
      "  with fiona.drivers():\n",
      "C:\\Users\\jesse.pisel\\AppData\\Local\\Continuum\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\geopandas\\io\\file.py:108: FionaDeprecationWarning: Use fiona.Env() instead.\n",
      "  with fiona.drivers():\n",
      "C:\\Users\\jesse.pisel\\AppData\\Local\\Continuum\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\geopandas\\io\\file.py:108: FionaDeprecationWarning: Use fiona.Env() instead.\n",
      "  with fiona.drivers():\n",
      "C:\\Users\\jesse.pisel\\AppData\\Local\\Continuum\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\geopandas\\io\\file.py:108: FionaDeprecationWarning: Use fiona.Env() instead.\n",
      "  with fiona.drivers():\n",
      "C:\\Users\\jesse.pisel\\AppData\\Local\\Continuum\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\geopandas\\io\\file.py:108: FionaDeprecationWarning: Use fiona.Env() instead.\n",
      "  with fiona.drivers():\n",
      "C:\\Users\\jesse.pisel\\AppData\\Local\\Continuum\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\geopandas\\io\\file.py:108: FionaDeprecationWarning: Use fiona.Env() instead.\n",
      "  with fiona.drivers():\n",
      "C:\\Users\\jesse.pisel\\AppData\\Local\\Continuum\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\geopandas\\io\\file.py:108: FionaDeprecationWarning: Use fiona.Env() instead.\n",
      "  with fiona.drivers():\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run this for all combinations of 2 tops and KNN\n",
    "\n",
    "\n",
    "for j in enumerate(topcombos):\n",
    "    tops_api = pd.read_csv(r\"D:\\jupyter\\EarlyWSGS\\ftunion.csv\").fillna(\n",
    "        0\n",
    "    )  # this file is available in the unconformity or onlap folder in the repo\n",
    "    fmtops = list(topcombos[j[0]])\n",
    "    fmtops.extend([\"x\", \"y\"])\n",
    "    tops = tops_api[fmtops]\n",
    "\n",
    "    # calculate thicknesses and neighbors for the two tops\n",
    "    hood = squareform(pdist(tops.iloc[:, -2:]))\n",
    "    neighbors = []\n",
    "    for i in enumerate(hood.argsort()[0:, 1 : no_of_neighbors + 1]):\n",
    "        selected = (\n",
    "            tops.iloc[hood.argsort()[i[0], 1 : no_of_neighbors + 1], 0:-2]\n",
    "            .stack()\n",
    "            .to_frame()\n",
    "            .T\n",
    "        )\n",
    "        selected.columns = selected.columns.droplevel()\n",
    "        neighbors.append(selected)\n",
    "    frame = pd.concat(neighbors, sort=False)\n",
    "    frame.index = range(len(frame))\n",
    "    neighborhood = pd.concat([tops.iloc[:, :-2], frame], axis=1)\n",
    "    thicknesses = neighborhood.diff(axis=1) * -1\n",
    "    thicknesses[thicknesses < 0] = 0\n",
    "    thicknesses.drop(columns=tops.columns[0], inplace=True)\n",
    "    thicknesses[thicknesses < 0] = 0\n",
    "    thicknesses[thicknesses > 3000] = 0\n",
    "    locations = tops[[\"x\", \"y\"]]\n",
    "    real_world_log = thicknesses.apply(\n",
    "        np.log\n",
    "    )  # take the log of thicknesses for feature engineering\n",
    "    real_world_pow = thicknesses.apply(\n",
    "        lambda x: x ** 10\n",
    "    )  # calculates the power values of thickness for another feature\n",
    "    rw = (\n",
    "        pd.concat(\n",
    "            [thicknesses, real_world_log, real_world_pow, locations],\n",
    "            axis=1,\n",
    "            join_axes=[thicknesses.index],\n",
    "        )\n",
    "        .dropna()\n",
    "        .replace(-np.inf, 0)\n",
    "    )\n",
    "    normalized_rw = (rw - rw.min()) / (rw.max() - rw.min()).replace(\n",
    "        0, 0.00001\n",
    "    )  # normalize the data from 0 to 1\n",
    "    real_data = normalized_rw.values\n",
    "\n",
    "    # load up the well location data and merge it with the tops data\n",
    "    well_locs = pd.read_csv(\n",
    "        r\"D:\\jupyter\\EarlyWSGS\\well_locations.csv\", encoding=\"ISO-8859-1\"\n",
    "    )\n",
    "    well_preds = neigh.predict(real_data)\n",
    "    well_prob = neigh.predict_proba(real_data)\n",
    "    probs = []\n",
    "    for i in range(len(well_prob)):\n",
    "        probs.append(well_prob[i].max())\n",
    "    tops_api[\"predictionknn\"] = well_preds\n",
    "    tops_api['probability'] = probs\n",
    "    merged = pd.merge(tops_api, well_locs, on=\"API\")\n",
    "    plt.scatter(\n",
    "        merged[merged[\"predictionknn\"] == 0].LON,\n",
    "        merged[merged[\"predictionknn\"] == 0].LAT,\n",
    "        label=\"Angular Unconformity\",\n",
    "    )\n",
    "    plt.scatter(\n",
    "        merged[merged[\"predictionknn\"] == 1].LON,\n",
    "        merged[merged[\"predictionknn\"] == 1].LAT,\n",
    "        label=\"Onlap\",\n",
    "    )\n",
    "    plt.scatter(\n",
    "        merged[merged[\"predictionknn\"] == 2].LON,\n",
    "        merged[merged[\"predictionknn\"] == 2].LAT,\n",
    "        label=\"Horizontally Stratified\",\n",
    "    )\n",
    "    plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "    plt.title(\"KNN Predictions\")\n",
    "    plt.savefig(r\"D:/predictions/\" + str(topcombos[j[0]]) + \"_KNN.jpg\")\n",
    "    plt.clf()\n",
    "\n",
    "    # writes the point data to a shapefile in the dir called data.shp\n",
    "    geometry = [Point(xy) for xy in zip(merged.LON, merged.LAT)]\n",
    "    crs = {\"init\": \"epsg:3732\"}\n",
    "    geo_df = GeoDataFrame(merged, crs={\"init\": \"epsg:4326\"}, geometry=geometry)\n",
    "    geo_df.to_file(\n",
    "        driver=\"ESRI Shapefile\",\n",
    "        filename=\"D:/predictions/shapefiles/\"\n",
    "        + str(topcombos[j[0]])\n",
    "        + \"_KNN_predictions.shp\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
