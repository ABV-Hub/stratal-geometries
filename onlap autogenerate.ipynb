{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import itertools\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "import fiona\n",
    "\n",
    "%matplotlib inline\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_tops = 2\n",
    "no_of_neighbors = 20\n",
    "\n",
    "dataset = pd.read_csv(\n",
    "    r\"F:/Geology/WSGS/Projects/jupyter/\" + str(number_of_tops) + \"layers\"+str(no_of_neighbors)+\"neighbors.csv\",\n",
    "    index_col=[0],\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# next let's split our toy data into training and test sets, choose how much with test_size of the data becomes the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset.iloc[0:, 0:-1].values,\n",
    "    dataset.iloc[0:, -1].values,\n",
    "    test_size=0.1,\n",
    "    random_state=86,\n",
    ")\n",
    "tops_api = pd.read_csv(r\"F:\\Geology\\WSGS\\Projects\\jupyter\\EarlyWSGS\\ftunion.csv\").fillna(\n",
    "    0\n",
    ")  # this file is available in the unconformity or onlap folder in the repo\n",
    "\n",
    "iterable = [\"Kfh\", \"Klz\", \"Kll\", \"Klr\", \"Kl\", \"Tfc\", \"Tfb\", \"Tfob\", \"Tfu\"]\n",
    "topcombos = list(zip(iterable, iterable[1:]))\n",
    "topcombos.append((\"Kfh\", \"Kl\"))\n",
    "topcombos.append((\"Kl\", \"Tfu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=10)\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed: 38.5min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_params = {\n",
    "    'n_neighbors' : [1,4,5,11,19,25],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan'],\n",
    "\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(KNeighborsClassifier(), grid_params, verbose=1, cv=2, n_jobs =5)\n",
    "gs_results = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999455337690633"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'manhattan', 'n_neighbors': 4, 'weights': 'distance'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
    "           metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
    "           weights='distance')\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = neigh.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scikitplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-2c128afca975>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mscikitplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mskplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mskplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#plt.savefig('confusion matrix figure.pdf')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scikitplot'"
     ]
    }
   ],
   "source": [
    "import scikitplot as skplt\n",
    "skplt.metrics.plot_confusion_matrix(y_test, y_pred, normalize=True)\n",
    "#plt.savefig('confusion matrix figure.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jrp4932\\AppData\\Local\\Continuum\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\ipykernel_launcher.py:43: FutureWarning: The join_axes-keyword is deprecated. Use .reindex or .reindex_like on the result to achieve the same functionality.\n",
      "C:\\Users\\jrp4932\\AppData\\Local\\Continuum\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\ipykernel_launcher.py:43: FutureWarning: The join_axes-keyword is deprecated. Use .reindex or .reindex_like on the result to achieve the same functionality.\n",
      "C:\\Users\\jrp4932\\AppData\\Local\\Continuum\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\ipykernel_launcher.py:43: FutureWarning: The join_axes-keyword is deprecated. Use .reindex or .reindex_like on the result to achieve the same functionality.\n",
      "C:\\Users\\jrp4932\\AppData\\Local\\Continuum\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\ipykernel_launcher.py:43: FutureWarning: The join_axes-keyword is deprecated. Use .reindex or .reindex_like on the result to achieve the same functionality.\n",
      "C:\\Users\\jrp4932\\AppData\\Local\\Continuum\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\ipykernel_launcher.py:43: FutureWarning: The join_axes-keyword is deprecated. Use .reindex or .reindex_like on the result to achieve the same functionality.\n",
      "C:\\Users\\jrp4932\\AppData\\Local\\Continuum\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\ipykernel_launcher.py:43: FutureWarning: The join_axes-keyword is deprecated. Use .reindex or .reindex_like on the result to achieve the same functionality.\n",
      "C:\\Users\\jrp4932\\AppData\\Local\\Continuum\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\ipykernel_launcher.py:43: FutureWarning: The join_axes-keyword is deprecated. Use .reindex or .reindex_like on the result to achieve the same functionality.\n",
      "C:\\Users\\jrp4932\\AppData\\Local\\Continuum\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\ipykernel_launcher.py:43: FutureWarning: The join_axes-keyword is deprecated. Use .reindex or .reindex_like on the result to achieve the same functionality.\n",
      "C:\\Users\\jrp4932\\AppData\\Local\\Continuum\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\ipykernel_launcher.py:43: FutureWarning: The join_axes-keyword is deprecated. Use .reindex or .reindex_like on the result to achieve the same functionality.\n",
      "C:\\Users\\jrp4932\\AppData\\Local\\Continuum\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\ipykernel_launcher.py:43: FutureWarning: The join_axes-keyword is deprecated. Use .reindex or .reindex_like on the result to achieve the same functionality.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run this for all combinations of 2 tops and KNN\n",
    "\n",
    "\n",
    "for j in enumerate(topcombos):\n",
    "    tops_api = pd.read_csv(r\"F:\\Geology\\WSGS\\Projects\\jupyter\\EarlyWSGS\\ftunion.csv\").fillna(\n",
    "        0\n",
    "    )  # this file is available in the unconformity or onlap folder in the repo\n",
    "    fmtops = list(topcombos[j[0]])\n",
    "    fmtops.extend([\"x\", \"y\"])\n",
    "    tops = tops_api[fmtops]\n",
    "\n",
    "    # calculate thicknesses and neighbors for the two tops\n",
    "    hood = squareform(pdist(tops.iloc[:, -2:]))\n",
    "    neighbors = []\n",
    "    for i in enumerate(hood.argsort()[0:, 1 : no_of_neighbors + 1]):\n",
    "        selected = (\n",
    "            tops.iloc[hood.argsort()[i[0], 1 : no_of_neighbors + 1], 0:-2]\n",
    "            .stack()\n",
    "            .to_frame()\n",
    "            .T\n",
    "        )\n",
    "        selected.columns = selected.columns.droplevel()\n",
    "        neighbors.append(selected)\n",
    "    frame = pd.concat(neighbors, sort=False)\n",
    "    frame.index = range(len(frame))\n",
    "    neighborhood = pd.concat([tops.iloc[:, :-2], frame], axis=1)\n",
    "    thicknesses = neighborhood.diff(axis=1) * -1\n",
    "    thicknesses[thicknesses < 0] = 0\n",
    "    thicknesses.drop(columns=tops.columns[0], inplace=True)\n",
    "    thicknesses[thicknesses < 0] = 0\n",
    "    thicknesses[thicknesses > 3000] = 0\n",
    "    locations = tops[[\"x\", \"y\"]]\n",
    "    real_world_log = thicknesses.apply(\n",
    "        np.log\n",
    "    )  # take the log of thicknesses for feature engineering\n",
    "    real_world_pow = thicknesses.apply(\n",
    "        lambda x: x ** 10\n",
    "    )  # calculates the power values of thickness for another feature\n",
    "    rw = (\n",
    "        pd.concat(\n",
    "            [thicknesses, real_world_log, real_world_pow, locations],\n",
    "            axis=1,\n",
    "            join_axes=[thicknesses.index],\n",
    "        )\n",
    "        .dropna()\n",
    "        .replace(-np.inf, 0)\n",
    "    )\n",
    "    normalized_rw = (rw - rw.min()) / (rw.max() - rw.min()).replace(\n",
    "        0, 0.00001\n",
    "    )  # normalize the data from 0 to 1\n",
    "    real_data = normalized_rw.values\n",
    "\n",
    "    # load up the well location data and merge it with the tops data\n",
    "    well_locs = pd.read_csv(\n",
    "        r\"F:\\Geology\\WSGS\\Projects\\jupyter\\EarlyWSGS\\well_locations.csv\", encoding=\"ISO-8859-1\"\n",
    "    )\n",
    "    well_preds = neigh.predict(real_data) #knn predictions\n",
    "    well_prob = neigh.predict_proba(real_data) #knn predictions\n",
    "    probs = []\n",
    "    for i in range(len(well_prob)):\n",
    "        probs.append(well_prob[i].max())\n",
    "    tops_api[\"predictionknn\"] = well_preds\n",
    "    tops_api['probability'] = probs\n",
    "    merged = pd.merge(tops_api, well_locs, on=\"API\")\n",
    "    plt.scatter(\n",
    "        merged[merged[\"predictionknn\"] == 0].LON,\n",
    "        merged[merged[\"predictionknn\"] == 0].LAT,\n",
    "        label=\"Angular Unconformity\",\n",
    "    )\n",
    "    plt.scatter(\n",
    "        merged[merged[\"predictionknn\"] == 1].LON,\n",
    "        merged[merged[\"predictionknn\"] == 1].LAT,\n",
    "        label=\"Onlap\",\n",
    "    )\n",
    "    plt.scatter(\n",
    "        merged[merged[\"predictionknn\"] == 2].LON,\n",
    "        merged[merged[\"predictionknn\"] == 2].LAT,\n",
    "        label=\"Horizontally Stratified\",\n",
    "    )\n",
    "    plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "    plt.title(\"KNN Predictions\")\n",
    "    plt.savefig(r\"new \" + str(topcombos[j[0]]) + \"_KNN2020.jpg\")\n",
    "    plt.clf()\n",
    "\n",
    "    # writes the point data to a shapefile in the dir called data.shp\n",
    "    geometry = [Point(xy) for xy in zip(merged.LON, merged.LAT)]\n",
    "    crs = {\"init\": \"epsg:3732\"}\n",
    "    geo_df = GeoDataFrame(merged, crs={\"init\": \"epsg:4326\"}, geometry=geometry)\n",
    "    geo_df.to_file(\n",
    "        driver=\"ESRI Shapefile\",\n",
    "        filename=\"F:/Geology/WSGS/Projects/Unconformity or onlap/predictions/shapefiles/\"\n",
    "        + str(topcombos[j[0]])\n",
    "        + \"_knn_predictions.shp\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
